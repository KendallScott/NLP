{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SXIqTNN-aWr",
        "outputId": "7f358de2-201f-4e35-b7aa-6920f832fd60"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Levenshtein\n",
            "  Downloading Levenshtein-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/174.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein)\n",
            "  Downloading rapidfuzz-3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.21.0 rapidfuzz-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install NlpToolkit-MorphologicalAnalysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-RRZPCwjD6H",
        "outputId": "13ed94b0-dab3-4edd-a791-d13c9fa8fe0e"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting NlpToolkit-MorphologicalAnalysis\n",
            "  Downloading NlpToolkit-MorphologicalAnalysis-1.0.47.tar.gz (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting NlpToolkit-Dictionary (from NlpToolkit-MorphologicalAnalysis)\n",
            "  Downloading NlpToolkit-Dictionary-1.0.34.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting NlpToolkit-Corpus (from NlpToolkit-MorphologicalAnalysis)\n",
            "  Downloading NlpToolkit-Corpus-1.0.25.tar.gz (23 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting NlpToolkit-DataStructure (from NlpToolkit-MorphologicalAnalysis)\n",
            "  Downloading NlpToolkit-DataStructure-1.0.14.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting NlpToolkit-Math (from NlpToolkit-Dictionary->NlpToolkit-MorphologicalAnalysis)\n",
            "  Downloading NlpToolkit-Math-1.0.18.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NlpToolkit-MorphologicalAnalysis, NlpToolkit-Corpus, NlpToolkit-DataStructure, NlpToolkit-Dictionary, NlpToolkit-Math\n",
            "  Building wheel for NlpToolkit-MorphologicalAnalysis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NlpToolkit-MorphologicalAnalysis: filename=NlpToolkit_MorphologicalAnalysis-1.0.47-py3-none-any.whl size=63212 sha256=6e634742f82a9b029f208621faeb61b41d6c6676bcd5c3401c5c94463024d4d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/17/da/eb2062d3efd3f84ec1fa752fcfc886b8238c4063527e878cce\n",
            "  Building wheel for NlpToolkit-Corpus (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NlpToolkit-Corpus: filename=NlpToolkit_Corpus-1.0.25-py3-none-any.whl size=27668 sha256=486e5f4f878d6315dd75751b5ebd6b82420bd9226728a271d268a59d75ede255\n",
            "  Stored in directory: /root/.cache/pip/wheels/4d/e0/72/616785dea01e638b274405fa7d314bd8e2b64f7fbfa9dd19bc\n",
            "  Building wheel for NlpToolkit-DataStructure (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NlpToolkit-DataStructure: filename=NlpToolkit_DataStructure-1.0.14-py3-none-any.whl size=23762 sha256=aefd3117174fd1286abb15323c2a710832f303938826b4e233b645bcd2ad6076\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/c2/ff/c54f7a5400ef906937fd1ee01296415555c31b8ebfc47dbb22\n",
            "  Building wheel for NlpToolkit-Dictionary (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NlpToolkit-Dictionary: filename=NlpToolkit_Dictionary-1.0.34-py3-none-any.whl size=1357917 sha256=57d3dfa1d4d23dbcbf1f45fbb96c6071d44d0ecfa1a10b15f87712b4ab8b2202\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/8f/01/6af1297e548b2b5b595bfe73f57667c19bdfe2c8affe8001e7\n",
            "  Building wheel for NlpToolkit-Math (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NlpToolkit-Math: filename=NlpToolkit_Math-1.0.18-py3-none-any.whl size=30307 sha256=97caefbde1d0bdcc64c88395c4372224e52e7d74230a9a9dfd5d95d22dfcceaf\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/24/80/f8aefdfa0b8b7c3cef7b3a2b24fc2ed86d781c88eb48125d28\n",
            "Successfully built NlpToolkit-MorphologicalAnalysis NlpToolkit-Corpus NlpToolkit-DataStructure NlpToolkit-Dictionary NlpToolkit-Math\n",
            "Installing collected packages: NlpToolkit-Math, NlpToolkit-DataStructure, NlpToolkit-Dictionary, NlpToolkit-Corpus, NlpToolkit-MorphologicalAnalysis\n",
            "Successfully installed NlpToolkit-Corpus-1.0.25 NlpToolkit-DataStructure-1.0.14 NlpToolkit-Dictionary-1.0.34 NlpToolkit-Math-1.0.18 NlpToolkit-MorphologicalAnalysis-1.0.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Homework 3\n",
        "1. Compare your given name with your nickname (if you don’t have a nickname, invent one for this\n",
        "assignment) by answering the following questions:\n",
        "\n",
        "a. What is the edit distance between your nickname and your given name?\n",
        "\n",
        "b. What is the percentage string match between your nickname and your given name?\n",
        "\n",
        "Show your work for both calculations."
      ],
      "metadata": {
        "id": "dFJnKDty8SD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ". What is the edit distance between your nickname and your given name?"
      ],
      "metadata": {
        "id": "dsFrPqIQ_Tz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "import Levenshtein as lev\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "id": "QLqg5duUdx48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lev.distance('Kendall', 'Ken doll')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4LIWjLR-YIj",
        "outputId": "e11a79cb-13a9-41f5-d62a-e423d1d2fda0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. What is the percentage string match between your nickname and your given name?"
      ],
      "metadata": {
        "id": "c7AGR26B_YM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(len('Kendall')-lev.distance('Kendall', 'Ken doll'))/len('Kendall')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvP7aVVI_Y2c",
        "outputId": "59fb5860-c1af-42f2-f316-b7bb82e10e2b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7142857142857143"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2. Find a friend (or family member or classmate) who you know has read a certain book. Without your friend knowing, copy the first two sentences of that book. Now rewrite the words from those sentences, excluding stop words. Now tell your friend to guess which book the words are from by reading them just that list of words. Did you friend correctly guess the book on the first try? \n"
      ],
      "metadata": {
        "id": "sKj_zK7m_uZ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TGrCyXuI8RfT"
      },
      "outputs": [],
      "source": [
        "body_keeps_score=\"One does not have be a combat soldier, or visit a refugee camp in Syria or the Congo to encounter trauma. Trauma happens to us, our friends, our families, and our neighbors. Research by the Centers for Disease Control and Prevention has shown that one in five Americans was sexually molested as a child; one in four was beaten by a parent to the point of a mark being left on their body; and one in three couples engages in physical violence. A quarter of us grew up with alcoholic relatives, and one out of eight witnessed their mother being beaten or hit.1 As human beings we belong to an extremely resilient species. Since time immemorial we have rebounded from our relentless wars, countless disasters (both natural and man-made), and the violence and betrayal in our own lives. But traumatic experiences do leave traces, whether on a large scale (on our histories and cultures) or close to home, on our families, with dark secrets being imperceptibly passed down through generations. They also leave traces on our minds and emotions, on our capacity for joy and intimacy, and even on our biology and immune systems.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_sentence = remove_stopwords(body_keeps_score)"
      ],
      "metadata": {
        "id": "w64q9SnT9oid"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "pLVZMJmu9sFB",
        "outputId": "a52cfef2-8dba-49fb-d6cb-197eea31f1c8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'One combat soldier, visit refugee camp Syria Congo encounter trauma. Trauma happens us, friends, families, neighbors. Research Centers Disease Control Prevention shown Americans sexually molested child; beaten parent point mark left body; couples engages physical violence. A quarter grew alcoholic relatives, witnessed mother beaten hit.1 As human beings belong extremely resilient species. Since time immemorial rebounded relentless wars, countless disasters (both natural man-made), violence betrayal lives. But traumatic experiences leave traces, large scale (on histories cultures) close home, families, dark secrets imperceptibly passed generations. They leave traces minds emotions, capacity joy intimacy, biology immune systems.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What did he or she guess? \n",
        "Explain why you think you friend either was or was not able to guess the book from hearing the list of words.\n"
      ],
      "metadata": {
        "id": "NqpSXNLe_-F8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "He guessed The Body Keeps the Score correctly, which is a book I knew he is currently reading, and I believe the subject matter is also relatively unique, and would not appear regularly in other books (trauma, sexual violence, war, etc.)."
      ],
      "metadata": {
        "id": "xzisybI5AOem"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3. Run one of the stemmers available in Python. Run the same two sentences from question 2 above through the stemmer and show the results. \n",
        "\n"
      ],
      "metadata": {
        "id": "lfyELq9-_wwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting sentence to array of words\n",
        "def convert(body_keeps_score):\n",
        "    return ''.join(body_keeps_score).split()"
      ],
      "metadata": {
        "id": "_aSCgxl_BVvM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "body_keeps_score=( convert(body_keeps_score))"
      ],
      "metadata": {
        "id": "lLvS7N0xBeBO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(body_keeps_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bSj_eXyC2tZ",
        "outputId": "20bdc28a-d8ff-4b65-aece-ba2f4e8954a0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "194"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Python porter stemmer\n",
        "ps = PorterStemmer()\n",
        "\n",
        "#saving list of original, stemmed, and levenshtein distance into an array-- to compile into pandas dataframe later \n",
        "WNL = WordNetLemmatizer()\n",
        "\n",
        "stem = []\n",
        "regular = []\n",
        "levenshtein = []\n",
        "stem_WNL = []\n",
        "regular_WNL = []\n",
        "\n",
        "i=0\n",
        "# Perform stemming\n",
        "for word in body_keeps_score:\n",
        "   stem.append(ps.stem(body_keeps_score[i]))\n",
        "   regular.append(body_keeps_score[i])\n",
        "   levenshtein.append(lev.distance(body_keeps_score[i], ps.stem(body_keeps_score[i])))\n",
        "\n",
        "   i+=1"
      ],
      "metadata": {
        "id": "lQdTa14bEz3r"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemming_ex1 = pd.DataFrame({'stemmed': list(stem), 'regular': list(regular), 'levenshtein': list(levenshtein)}, columns=['stemmed', 'regular', 'levenshtein'])\n",
        "stemming_ex1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "s--zV4dkGP8d",
        "outputId": "121626ab-0820-40d5-c350-d75e70f6a8c2"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      stemmed   regular  levenshtein\n",
              "0         one       One            1\n",
              "1         doe      does            1\n",
              "2         not       not            0\n",
              "3        have      have            0\n",
              "4          be        be            0\n",
              "..        ...       ...          ...\n",
              "189       our       our            0\n",
              "190    biolog   biology            1\n",
              "191       and       and            0\n",
              "192     immun    immune            1\n",
              "193  systems.  systems.            0\n",
              "\n",
              "[194 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f94f820a-cdc4-4c02-9bbe-0d0277de4ed2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stemmed</th>\n",
              "      <th>regular</th>\n",
              "      <th>levenshtein</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one</td>\n",
              "      <td>One</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>doe</td>\n",
              "      <td>does</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>not</td>\n",
              "      <td>not</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>have</td>\n",
              "      <td>have</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>be</td>\n",
              "      <td>be</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>our</td>\n",
              "      <td>our</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>biolog</td>\n",
              "      <td>biology</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>and</td>\n",
              "      <td>and</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>immun</td>\n",
              "      <td>immune</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>systems.</td>\n",
              "      <td>systems.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>194 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f94f820a-cdc4-4c02-9bbe-0d0277de4ed2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f94f820a-cdc4-4c02-9bbe-0d0277de4ed2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f94f820a-cdc4-4c02-9bbe-0d0277de4ed2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "Morphological_diff = []\n",
        "i=0\n",
        "# Perform stemming\n",
        "for word in body_keeps_score:\n",
        "  Morphological_diff.append(lev.distance(lemmatizer.lemmatize(stemming_ex1['stemmed'][i].lower()), lemmatizer.lemmatize(stemming_ex1['regular'][i]).lower()))\n",
        "  i+=1"
      ],
      "metadata": {
        "id": "KX97kD2MjrSz"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many of the outputted stems are valid morphological roots of the corresponding words? \n",
        "\n",
        "Express this answer as a percentage.\n"
      ],
      "metadata": {
        "id": "a0OJmlaToqZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Morphological_diff.count(0)/len(Morphological_diff)\n",
        "#80% of the words are valud morphological words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFTUJZk0fsvA",
        "outputId": "99a31b23-8b51-418f-d759-441a6660085c"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7989690721649485"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    }
  ]
}
